{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note:\n",
    "# if youre training on a server thru SSH, i would recommend you use the .py file\n",
    "# for training, as this would let you remount a TMUX terminmal if you disconnect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###   CONFIGURATION   ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from IPython.display import clear_output\n",
    "import tokenizer\n",
    "import os\n",
    "import math\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec\n",
    "model_file = fr\"./embedding_models/YOUR_GENSIM_MODEL_NAME.model\"\n",
    "embeddings_model = Word2Vec.load(model_file)\n",
    "\n",
    "vector_size = embeddings_model.vector_size        # aka embedding dim \n",
    "\n",
    "# neural net settings\n",
    "weights_file = fr\"./REAN_weights/YOUR_PYTORCH_FILE.pth\"\n",
    "\n",
    "context_length = 128                              # tokens to consider\n",
    "attn_heads = 8                                    # num attention heads per mechanism (per transformer block)\n",
    "dropout_prob = 0.0                                # 0.0 ---> everything normal   |   1.0 ---> everything is random\n",
    "\n",
    "# pytorch\n",
    "run_device = torch.device(\"cuda\")\n",
    "storage_device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###   NEURAL NET ARCHITECTURE   ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class leaky_tanh_smart(nn.Module):\n",
    "    def __init__(self, leaky_range=(0, 3), squishy_range=(0, 3)):\n",
    "        super(leaky_tanh_smart, self).__init__()\n",
    "        # register leakyness and squishyness as trainable parameters\n",
    "        self.leakyness = nn.Parameter(torch.rand(1, dtype=torch.float32) * (leaky_range[1] - leaky_range[0]) + leaky_range[0])\n",
    "        self.squishyness = nn.Parameter(torch.rand(1, dtype=torch.float32) * (squishy_range[1] - squishy_range[0]) + squishy_range[0])\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        applies the leaky tanh activation function over the input tensor x.\\n\n",
    "        for more info on leaky tanh and its parameters go to: https://www.desmos.com/calculator/kpzsfbtqww\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): tensor over which to apply activation function.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: returns x after function applied, keeps the same shape.\n",
    "        \"\"\"\n",
    "        \n",
    "        return F.tanh(x * self.squishyness) + self.leakyness * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention_mech(nn.Module):\n",
    "    def __init__(self, vector_size=vector_size, attn_heads=attn_heads):\n",
    "        super(attention_mech, self).__init__()\n",
    "        # MultiheadAttention module\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=vector_size, num_heads=attn_heads)\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.norm = nn.LayerNorm(vector_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Prepare for multi-head attention (transpose to (sentence_len, batch_size, embedding_dim))\n",
    "        x = x.transpose(0, 1)\n",
    "        \n",
    "        # Create causal mask\n",
    "        seq_len = x.size(0)\n",
    "        causal_mask = torch.triu(torch.ones((seq_len, seq_len), device=x.device), diagonal=1).bool()\n",
    "        \n",
    "        # Apply multi-head attention with the causal mask\n",
    "        attn_output, attn_weights = self.multihead_attn(x, x, x, attn_mask=causal_mask)\n",
    "        \n",
    "        # Apply layer normalization to the attention output\n",
    "        attn_output = self.norm(attn_output)\n",
    "        \n",
    "        # Transpose back to (batch_size, sentence_len, embedding_dim)\n",
    "        output = attn_output.transpose(0, 1)\n",
    "        \n",
    "        return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class positional_encoding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(positional_encoding, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, context_length, vector_size = x.size()\n",
    "\n",
    "        # Generate positions (shape: [context_length, 1])\n",
    "        position = torch.arange(0, context_length, dtype=torch.float).unsqueeze(1).to(x.device)\n",
    "\n",
    "        # Compute the divisor term (shape: [vector_size // 2])\n",
    "        div_term = torch.exp(torch.arange(0, vector_size, 2).float() * (-math.log(10000.0) / vector_size)).to(x.device)\n",
    "\n",
    "        # Initialize positional encoding tensor (shape: [context_length, vector_size])\n",
    "        pe = torch.zeros(context_length, vector_size, device=x.device)\n",
    "        \n",
    "        # Apply sine to even indices and cosine to odd indices\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # sine for even indices\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # cosine for odd indices\n",
    "\n",
    "        # Add positional encoding to the input\n",
    "        x = x + pe.unsqueeze(0)  # Add positional encoding, shape becomes (batch_size, context_length, vector_size)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class transformer_block(nn.Module):\n",
    "    def __init__(self, vector_size=vector_size):\n",
    "        super(transformer_block, self).__init__()\n",
    "        \n",
    "        self.activ_func = leaky_tanh_smart()\n",
    "        \n",
    "        self.attn = attention_mech()\n",
    "        \n",
    "        self.fc = nn.Linear(vector_size, vector_size)\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(vector_size)\n",
    "        self.norm2 = nn.LayerNorm(vector_size)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.norm1(x + self.attn(x)[0])\n",
    "        x = self.norm2(x + self.activ_func(self.fc(x)))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class REAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(REAN, self).__init__()\n",
    "        \n",
    "        self.pos_encoding = positional_encoding()\n",
    "        \n",
    "        self.tblock1 = transformer_block()\n",
    "        self.tblock2 = transformer_block()\n",
    "        self.tblock3 = transformer_block()\n",
    "        self.tblock4 = transformer_block()\n",
    "\n",
    "    def forward(self, segment: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        this function is primarily used for training, where the network needs to predict the next token, for every token in the sequence\n",
    "        \n",
    "        Args:\n",
    "            segment (torch.Tensor): this is a tensor of size (batches, context_length, vector_size) representing a sequence of tokens (of course from the tokenizer and using the correct word2vec model)\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: a tensor of shape (batches, context_length, vector_size) (same as segment) representing the sequence predicted by the network shifted future-way\n",
    "        \"\"\"\n",
    "        \n",
    "        ###                  INPUT                 ###\n",
    "        #    (batches, context_len, vector_size)\n",
    "        #                      ↓\n",
    "        \n",
    "        segment = self.pos_encoding(segment)\n",
    "        \n",
    "        segment = self.tblock1(segment)\n",
    "        segment = self.tblock2(segment)\n",
    "        segment = self.tblock3(segment)\n",
    "        segment = self.tblock4(segment)\n",
    "        \n",
    "        return segment\n",
    "    \n",
    "        #                      ↓\n",
    "        #    (batches, context_len, vector_size)\n",
    "        ###                 OUTPUT                 ###\n",
    "\n",
    "    def predict(self, segment: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        function is for predicting the embeddings vector of the next token in a given sequence\n",
    "        \n",
    "        Args:\n",
    "            segment (torch.Tensor): this is a tensor of size (batches, context_length, vector_size) representing a sequence of tokens (of course from the tokenizer and using the correct word2vec model)\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: a tensor of shape (batches, vector_size) representing the embeddings vector of the next token to be added into the sequence\n",
    "        \"\"\"\n",
    "        \n",
    "        ###                  INPUT                 ###\n",
    "        #    (batches, context_len, vector_size)\n",
    "        #                      ↓\n",
    "        \n",
    "        segment = self.forward(segment)\n",
    "        \n",
    "        return segment[:, -1, :]\n",
    "        \n",
    "        #                      ↓\n",
    "        #           (batches, vector_size)\n",
    "        ###                 OUTPUT                 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###   BUILD NET & DEPENDENCIES   ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load(weights_file)\n",
    "\n",
    "net.to(run_device)\n",
    "\n",
    "print(f\"neural net weight: {sum(param.numel() * param.element_size() for param in net.parameters()) / (1024 ** 3):.4f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###   UTIL FUNCS   ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_segment(segment: list[str], model: Word2Vec=embeddings_model, default: int = 0, used_device=storage_device) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    encodes all words in a given list to corresponding vectors in given model.\n",
    "    words not found in the model will be given a vector with \"default\" value\n",
    "    \n",
    "    Args:\n",
    "        sentence (list): list of strings (tokenized sentence)\n",
    "        model (Word2Vec): model to use when encoding\n",
    "        default (int): fill vector with this value if word is not found in model\n",
    "    \n",
    "    Returns:\n",
    "        np.array: 2d array with dim1 = len(sentence) and dim2 = model.vector_size\n",
    "    \"\"\"\n",
    "    \n",
    "    # generate inital array with default values\n",
    "    vectorized = np.ones((len(segment), model.vector_size)) * default\n",
    "    \n",
    "    # loop over every word in list\n",
    "    for current_word, current_word_idx in zip(segment, range(len(segment))):\n",
    "        # only add correct values if word is in model, otherwise leave as default\n",
    "        if current_word in model.wv:\n",
    "            # the try except block is needed because (current_word in model.wv) sometimes gives a false positive... yeah gensim\n",
    "            try:\n",
    "                vectorized[current_word_idx] = model.wv.get_vector(current_word, norm=False)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    vectorized = torch.tensor(vectorized, dtype=torch.float32, device=used_device)\n",
    "    \n",
    "    return vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def devectorize_segment(vectorized_segment: torch.Tensor, model: Word2Vec=embeddings_model, not_in_vocab_token=\"[NIV]\", NIV_threshold=0.01) -> list:\n",
    "    \"\"\"\n",
    "    decodes vectors into nearest word found in model, if no near words found, adds a not in vocab token\n",
    "    \n",
    "    Args:\n",
    "        vectorized_sentence (np.array): 2d arrat with vectors of words to be decoded\n",
    "        model (Word2Vec): model to use when decoding\n",
    "    \n",
    "    Returns:\n",
    "        list: list of strings (words) whos vectors most closely match those provided\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    # make sure vectors are ready to be processed\n",
    "    vectorized_segment = vectorized_segment.cpu().numpy()\n",
    "    \n",
    "    # go over all words and find closest match in model\n",
    "    for current_word in vectorized_segment:\n",
    "        similarities = model.wv.similar_by_vector(current_word)\n",
    "        \n",
    "        # check if its not a bullshit vector\n",
    "        if similarities[0][1] > NIV_threshold:\n",
    "            result.append(similarities[0][0])\n",
    "        else:\n",
    "            result.append(not_in_vocab_token)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_or_truncate(suspected_tensor: torch.tensor, target_length: int, default: int=0) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    pads or truncates a given tensor along dim 0 to target_length with \"default\" as padding\n",
    "    \n",
    "    Args:\n",
    "        suspected_tensor (torch.tensor): tensor to pad or truncate\n",
    "        target_length (int): target length of tensor\n",
    "        default (int): value to use for padding\n",
    "    \n",
    "    Returns:\n",
    "        torch.tensor: tensor of proper length no matter what\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(suspected_tensor) < target_length:\n",
    "        # pad\n",
    "        suspected_tensor = torch.cat((torch.ones(target_length - len(suspected_tensor), suspected_tensor.shape[1], dtype=torch.float32, device=suspected_tensor.device) * default, suspected_tensor))\n",
    "    else:\n",
    "        # truncate\n",
    "        suspected_tensor = suspected_tensor[-target_length:]\n",
    "    \n",
    "    return suspected_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_segment_for_net(segment: list[str], length: int=context_length, used_device: torch.DeviceObjType=storage_device):\n",
    "    \"\"\"\n",
    "    function to take a sentence, and do everything to make it possible to input into the net\n",
    "    \n",
    "    Args:\n",
    "        segment (list[str]): a list of tokens (ideally from the tokenizer) of a sentence / text\n",
    "        length (int): the number of tokens to which pad or truncate to. for correct operation: keep at the net's context length\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: tokenized segment in the correct length\n",
    "    \"\"\"\n",
    "    \n",
    "    # turn into embedding vectors\n",
    "    vectorized = vectorize_segment(segment, used_device=used_device)\n",
    "    \n",
    "    # trim / add into length\n",
    "    trimmed = pad_or_truncate(vectorized, length)\n",
    "    \n",
    "    # add fake batch dimension\n",
    "    batched = trimmed.unsqueeze(0)\n",
    "    \n",
    "    return batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_word(segment: list[str], net: REAN=net):\n",
    "    # turn tokenized text into net's format\n",
    "    prepared_segment = prepare_segment_for_net(segment, used_device=next(net.parameters()).device)\n",
    "    \n",
    "    # run net\n",
    "    prediction_vector = net.predict(prepared_segment).detach()\n",
    "    \n",
    "    # turn vector back into token\n",
    "    predicted_token = devectorize_segment(prediction_vector)\n",
    "    \n",
    "    return predicted_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequence(segment: list[str], num_tokens: int, net: REAN=net, display_tqdm=False):\n",
    "    result = segment.copy()\n",
    "    \n",
    "    for _ in tqdm(range(num_tokens), disable=not display_tqdm):\n",
    "        result += predict_word(result, net=net)\n",
    "    \n",
    "    return result[len(segment):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###   EVAL   ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"human: \" + \"write a list of the top 10 sports cars\" + \" network: \"\n",
    "tokens_to_predict = 128\n",
    "display_tqdm = True\n",
    "\n",
    "print(tokenizer.detokenize_segment(predict_sequence(tokenizer.tokenize_segment(prompt), tokens_to_predict, display_tqdm=display_tqdm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CONDA_VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
